{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LVLM-based Recommender Prompt Generation\n",
    "\n",
    "This notebook demonstrates the process of generating prompts for a LVLM-based recommender system. We will follow these steps:\n",
    "\n",
    "1. **Import Necessary Modules**: Import all the necessary modules and set up the project path.\n",
    "2. **Define the `PromptGenerator` Class**: Set up the `PromptGenerator` class.\n",
    "3. **Initialization**: Initialize the `PromptGenerator` class with the dataset.\n",
    "4. **Image Combination**: Combine images for history and target sequences.\n",
    "5. **Prompt Generation**: Generate prompts using different templates and explain their meanings.\n",
    "\n",
    "## Step 1: Import Necessary Modules\n",
    "\n",
    "First, we import all the necessary modules and set up the project path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from dataset import MRecDataset\n",
    "import json\n",
    "from prompt_templates import templates\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the `PromptGenerator` Class\n",
    "\n",
    "Next, we define the `PromptGenerator` class with the appropriate methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptGenerator(object):\n",
    "    def __init__(self, dataset, dataset_name, sample_size=None, max_seq_len=10, neg_num=29):\n",
    "        \"\"\"\n",
    "        Initialize the PromptGenerator class.\n",
    "\n",
    "        Parameters:\n",
    "        - dataset (object): The dataset object containing the data instances.\n",
    "        - dataset_name (str): The name of the dataset. Must be one of ['toys', 'beauty', 'sports', 'clothing'].\n",
    "        - sample_size (int, optional): The number of samples to generate. Default is None.\n",
    "        - max_seq_len (int, optional): The maximum sequence length. Default is 10.\n",
    "        - neg_num (int, optional): The number of negative samples. Default is 29.\n",
    "        \"\"\"\n",
    "        super(PromptGenerator, self).__init__()\n",
    "        dataset_choices = ['toys', 'beauty', 'sports', 'clothing']\n",
    "        if dataset_name not in dataset_choices:\n",
    "            raise ValueError(f'Invalid dataset: [{dataset_name}]. Only {dataset_choices} are supported.')\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset = dataset\n",
    "        self.interaction = {str(index+1): sublist for index, sublist in enumerate(self.dataset.instances())}\n",
    "\n",
    "        self.base_local_path = '../../datasets/Amazon_Review_Plus/photos/{}/'\n",
    "        self.base_online_path = 'https://hmdataset.oss-cn-guangzhou.aliyuncs.com/{}_{}_combine/'\n",
    "        self.sampled_photos_path = './sampled_photos/{}_{}/'\n",
    "        self.sampled_prompts_path = './sampled_prompts/{}_{}/'\n",
    "        \n",
    "        self.online_image_path = self.base_online_path.format(self.dataset_name, self.max_seq_len)\n",
    "        self.local_image_path = self.sampled_photos_path.format(self.dataset_name, self.max_seq_len)\n",
    "        self.saved_prompt_path = self.sampled_prompts_path.format(self.dataset_name, self.max_seq_len)\n",
    "\n",
    "        self.sample_size = sample_size\n",
    "        self.neg_num = neg_num\n",
    "        \n",
    "        if sample_size:\n",
    "            self.sample_interactions()\n",
    "\n",
    "    def read_tsv(self, path, datamap, item_pool_full):\n",
    "        \"\"\"\n",
    "        Read a TSV file and extract user-item interactions.\n",
    "\n",
    "        Parameters:\n",
    "        - path (str): The file path to the TSV file.\n",
    "        - datamap (dict): A dictionary mapping user and item IDs.\n",
    "        - item_pool_full (dict): A dictionary containing item details.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A dictionary with user IDs as keys and a list of item titles as values.\n",
    "        \"\"\"\n",
    "        with open(path, 'r', newline='') as file:\n",
    "            no_title = 0\n",
    "            tsv_reader = csv.reader(file, delimiter='\\t')\n",
    "            result = {}\n",
    "\n",
    "            for i, row in enumerate(tsv_reader):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                user = row[0]\n",
    "                items = row[1].split(\" \")\n",
    "                item_titles = []\n",
    "                user_id = datamap['user2id'][user]\n",
    "                for item in items:\n",
    "                    item_id = datamap['item2id'][item]\n",
    "                    if 'title' not in item_pool_full[item_id]:\n",
    "                        title = \"\"\n",
    "                        no_title += 1\n",
    "                    else:\n",
    "                        title = item_pool_full[item_id]['title']\n",
    "                    item_titles.append(title)\n",
    "                result[user_id] = item_titles\n",
    "            return result\n",
    "\n",
    "    def is_image_available(self, item_id):\n",
    "        \"\"\"\n",
    "        Check if an image is available for a given item ID.\n",
    "\n",
    "        Parameters:\n",
    "        - item_id (str): The item ID.\n",
    "\n",
    "        Returns:\n",
    "        - bool: True if the image is available, False otherwise.\n",
    "        \"\"\"\n",
    "        img_path = self.base_local_path.format(self.dataset_name) + self.dataset.id2img(item_id)\n",
    "        return os.path.exists(img_path) and 'No_Image_Available.jpg' not in img_path\n",
    "\n",
    "    def sample_interactions(self, seed=42):\n",
    "        \"\"\"\n",
    "        Sample interactions from the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - seed (int, optional): The random seed for sampling. Default is 42.\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "\n",
    "        original_count = len(self.interaction)\n",
    "        valid_keys = [key for key in self.interaction.keys() if all(self.is_image_available(item) for item in self.interaction[key])]\n",
    "        valid_count = len(valid_keys)\n",
    "\n",
    "        print(f\"Total interactions before filtering: {original_count}\")\n",
    "        print(f\"Total valid interactions after filtering: {valid_count}\")\n",
    "\n",
    "        if valid_count < self.sample_size:\n",
    "            raise ValueError(f\"Only {valid_count} valid interactions available, but {self.sample_size} samples are requested.\")\n",
    "\n",
    "        sampled_keys = random.sample(valid_keys, self.sample_size)\n",
    "        print(sampled_keys)\n",
    "        self.interaction = {key: self.interaction[key] for key in sampled_keys}\n",
    "\n",
    "    def save_image(self, all_images, label):\n",
    "        \"\"\"\n",
    "        Save images to local paths.\n",
    "\n",
    "        Parameters:\n",
    "        - all_images (dict): A dictionary with image paths.\n",
    "        - label (str): The label for the images.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.local_image_path):\n",
    "            os.makedirs(self.local_image_path)\n",
    "\n",
    "        for index, img_path_list in all_images.items():\n",
    "            images = [Image.open(img_path) for img_path in img_path_list]\n",
    "            num_images = len(images)\n",
    "\n",
    "            fig, axes = plt.subplots(1, num_images, figsize=(3*num_images, 3))\n",
    "            if num_images == 1:\n",
    "                axes = [axes]\n",
    "\n",
    "            for i, image in enumerate(images):\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].axis('off')\n",
    "\n",
    "            plt.savefig(self.local_image_path + '{}_{}.png'.format(index, label))\n",
    "            plt.close(fig)\n",
    "\n",
    "    def combine_images(self):\n",
    "        \"\"\"\n",
    "        Combine images for history and target sequences.\n",
    "        \"\"\"\n",
    "        history_image_dict = {}\n",
    "        target_image_dict = {}\n",
    "        for index, seq in self.interaction.items():\n",
    "            seq_images = [self.base_local_path.format(self.dataset_name) + self.dataset.id2img(_) for _ in seq]\n",
    "            history_image_dict[index] = seq_images[-self.max_seq_len-1:-1]\n",
    "            target_image_dict[index] = [seq_images[-1]]\n",
    "        self.save_image(history_image_dict, 'history')\n",
    "        self.save_image(target_image_dict, 'target')\n",
    "\n",
    "    def get_image_path_dict(self):\n",
    "        \"\"\"\n",
    "        Get a dictionary of image paths for history sequences.\n",
    "\n",
    "        Returns:\n",
    "        - dict: A dictionary with image paths.\n",
    "        \"\"\"\n",
    "        history_image_dict = {}\n",
    "        for index, seq in self.interaction.items():\n",
    "            seq_images = [self.base_local_path.format(self.dataset_name) + self.dataset.id2img(_) for _ in seq]\n",
    "            history_image_dict[index] = seq_images[-self.max_seq_len-1:-1]\n",
    "        return history_image_dict\n",
    "\n",
    "    def generate_prompts(self, template_id, templates, tsv_path=None, lvlm=\"claude3\"):\n",
    "        \"\"\"\n",
    "        Generate prompts using a specific template.\n",
    "\n",
    "        Parameters:\n",
    "        - template_id (str): The ID of the template to use.\n",
    "        - templates (dict): A dictionary of templates.\n",
    "        - tsv_path (str, optional): The file path to the TSV file.\n",
    "        - lvlm (str, optional): The language model to use. Default is \"claude3\".\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.saved_prompt_path):\n",
    "            os.makedirs(self.saved_prompt_path)\n",
    "        \n",
    "        template = templates[template_id].strip()\n",
    "        \n",
    "        prompts = {}\n",
    "\n",
    "        if template_id in ['s-1-image','s-1-title-image','s-1-title', 's-2', 's-3','s-4', 's-5']:\n",
    "            title_des = []\n",
    "\n",
    "            history_image_dict = self.get_image_path_dict()\n",
    "            for index, seq in self.interaction.items():\n",
    "                history_titles = []\n",
    "                for item in seq[-self.max_seq_len-1:-1]:\n",
    "                    try:\n",
    "                        title = self.dataset.item2side(item)['title']\n",
    "                    except KeyError:\n",
    "                        title = \"no_title\"\n",
    "                    history_titles.append(title)\n",
    "                for item_id, title in zip(seq[-self.max_seq_len-1:-1],history_titles):\n",
    "                    des = self.dataset.item2side(item_id)[\"image\"][\"image_description\"][lvlm].replace('\\n','')\n",
    "                    title_des.append(\"(title: {} | description: {})\".format(title,des))\n",
    "                target_title = self.dataset.item2side(seq[-1]).get('title', 'no_title')\n",
    "                candidate_titles = [target_title]\n",
    "                for item in self.dataset._user2neg[index][:self.neg_num]:\n",
    "                    try:\n",
    "                        title = self.dataset.item2side(item)['title']\n",
    "                    except KeyError:\n",
    "                        title = \"no_title\"\n",
    "                    candidate_titles.append(title)\n",
    "                random.shuffle(candidate_titles)\n",
    "                history_len = len(seq[-self.max_seq_len-1:-1])\n",
    "                candidate_len = self.neg_num+1\n",
    "                if template_id == 's-1-image':\n",
    "                    prompt = template.format(\n",
    "                        history_len, \n",
    "                        candidate_len, \n",
    "                        str(candidate_titles), \n",
    "                        candidate_len, \n",
    "                        candidate_len\n",
    "                        )\n",
    "                elif template_id == 's-1-title-image':\n",
    "                    prompt = template.format(\n",
    "                        history_len, \n",
    "                        str(history_titles),\n",
    "                        candidate_len, \n",
    "                        str(candidate_titles), \n",
    "                        candidate_len, \n",
    "                        candidate_len\n",
    "                        )\n",
    "                elif template_id == 's-1-title':\n",
    "                    prompt = template.format(\n",
    "                        history_len, \n",
    "                        str(history_titles),\n",
    "                        candidate_len, \n",
    "                        str(candidate_titles), \n",
    "                        candidate_len, \n",
    "                        candidate_len\n",
    "                        )\n",
    "                elif template_id == 's-3':\n",
    "                    datamap = self.dataset.datamaps\n",
    "                    item_pool_full = self.dataset.item_pool_full\n",
    "                    user_id2item_titles = self.read_tsv(tsv_path, datamap, item_pool_full)\n",
    "                    candidate_titles = user_id2item_titles[index]\n",
    "                    prompt = template.format(\n",
    "                        history_len, \n",
    "                        str(history_titles),\n",
    "                        str(candidate_titles), \n",
    "                        candidate_len, \n",
    "                        candidate_len\n",
    "                    )\n",
    "                elif template_id == 's-4':\n",
    "                    prompt = template.format(\n",
    "                        history_len, \n",
    "                        str(title_des),\n",
    "                        candidate_len, \n",
    "                        str(candidate_titles), \n",
    "                        candidate_len, \n",
    "                        candidate_len\n",
    "                    )\n",
    "                elif template_id == 's-5':\n",
    "                    datamap = self.dataset.datamaps\n",
    "                    item_pool_full = self.dataset.item_pool_full\n",
    "                    user_id2item_titles = self.read_tsv(tsv_path, datamap, item_pool_full)\n",
    "                    candidate_titles = user_id2item_titles[index]\n",
    "                    prompt = template.format(\n",
    "                        history_len, \n",
    "                        str(title_des),\n",
    "                        str(candidate_titles), \n",
    "                        candidate_len, \n",
    "                        candidate_len\n",
    "                    )\n",
    "                prompts[index] = {\n",
    "                    'prompt': prompt,\n",
    "                    'history': {\n",
    "                        'local_combined_image_path': self.local_image_path + '{}_{}.png'.format(index, 'history'),\n",
    "                        'online_combined_image_path': self.online_image_path + '{}_{}.png'.format(index, 'history'),\n",
    "                        'id': seq[-self.max_seq_len-1:-1],\n",
    "                        'titles': history_titles,\n",
    "                        'original_images_path': history_image_dict[index]\n",
    "                    },\n",
    "                    'candidate': {\n",
    "                        'titles': candidate_titles,\n",
    "                    },\n",
    "                    'target': {\n",
    "                        'local_image_path': self.local_image_path + '{}_{}.png'.format(index, 'target'),\n",
    "                        'online_image_path': self.online_image_path + '{}_{}.png'.format(index, 'target'),\n",
    "                        'id': [seq[-1]],\n",
    "                        'titles': [target_title]\n",
    "                    }\n",
    "                }\n",
    "        else:\n",
    "            raise ValueError(\"Invalid template ID provided.\")\n",
    "        \n",
    "        if template_id in [\"s-4\", \"s-5\"]:\n",
    "            json_file_path = self.saved_prompt_path + 'prompts_{}_{}.json'.format(template_id, lvlm)\n",
    "        else:\n",
    "            json_file_path = self.saved_prompt_path + 'prompts_{}.json'.format(template_id)\n",
    "        \n",
    "        with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(prompts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialization\n",
    "\n",
    "Next, we initialize the `PromptGenerator` class with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total interactions before filtering: 19412\n",
      "Total valid interactions after filtering: 19017\n",
      "['3732', '843', '9200', '8194', '7469', '4674', '3437', '18242', '2918', '14108']\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'toys'\n",
    "dataset = MRecDataset(root='../../datasets/Amazon_Review_Plus', dataset=dataset_name)\n",
    "\n",
    "sample_size = 10\n",
    "max_seq_len = 10\n",
    "neg_num = 29\n",
    "pg = PromptGenerator(dataset=dataset, dataset_name=dataset_name, sample_size=sample_size, neg_num=neg_num, max_seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Image Combination\n",
    "\n",
    "We combine images for history and target sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.combine_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prompt Generation\n",
    "\n",
    "Finally, we generate prompts using different templates. Here is the explanation of each template ID:\n",
    "\n",
    "- **s-1-title**: LVLMs as recommender using titles only.\n",
    "- **s-1-title-image**: LVLMs as recommender using both titles and images.\n",
    "- **s-1-image**: LVLMs as recommender using images only.\n",
    "- **s-3**: LVLMs as reranker using both titles and images.\n",
    "- **s-4**: LVLMs as item enhancer and recommender, using captions generated from images.\n",
    "- **s-5**: LVLMs as item enhancer and reranker, using captions generated from images.\n",
    "\n",
    "Note: For rerankers, tsv_path contains pre-ranked results from other recommenders, such as SASRec. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.generate_prompts('s-1-title', templates)\n",
    "pg.generate_prompts('s-1-title-image', templates)\n",
    "pg.generate_prompts('s-1-image', templates)\n",
    "pg.generate_prompts('s-3', templates, tsv_path=\"tsv_files/test_resultv20_toys_64_0.0001_VitConcatTitle-20240606-141603.tsv\")\n",
    "pg.generate_prompts('s-4', templates)\n",
    "pg.generate_prompts('s-5', templates, tsv_path=\"tsv_files/test_resultv20_toys_64_0.0001_VitConcatTitle-20240606-141603.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
